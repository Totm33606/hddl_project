{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d430bf-d898-4f88-bbec-f605ba17c476",
   "metadata": {},
   "source": [
    "# Mini-project n° 1 - Who painted this picture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db2b72-c086-45ed-9334-189b92543909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36316d9e-2ca9-48d0-ab47-bfa0e25a9433",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f874bd-41ef-4962-abe8-81db8d057c28",
   "metadata": {},
   "source": [
    "## Loading datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49247f1-829e-447a-a27a-094e9164be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./art-challenge/\"\n",
    "if not os.path.isdir(data_path) or not os.listdir(data_path):\n",
    "    !git clone https://plmlab.math.cnrs.fr/chevallier-teaching/datasets/art-challenge.git\n",
    "else:\n",
    "    print(\"Data already downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc621763-aed3-4b67-b919-fc75caf1a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV\n",
    "artists = pd.read_csv(data_path + \"artists.csv\")\n",
    "artists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43965d2",
   "metadata": {},
   "source": [
    "## Analyse exploratoire du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse descriptive des artistes et des styles\n",
    "print(\"Nombre total d'artistes :\", artists['name'].nunique())\n",
    "print(\"Nombre total de styles :\", artists['genre'].nunique())\n",
    "\n",
    "# Distribution des œuvres par artiste\n",
    "artists['paintings'].plot(kind='hist', bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Distribution des œuvres par artiste\")\n",
    "plt.xlabel(\"Nombre d'œuvres\")\n",
    "plt.ylabel(\"Nombre d'artistes\")\n",
    "plt.show()\n",
    "\n",
    "# Distribution des genres de peinture\n",
    "style_counts = artists['genre'].value_counts()\n",
    "style_counts.plot(kind='bar', color='lightgreen', edgecolor='black')\n",
    "plt.title(\"Nombre d'artistes par style de peinture\")\n",
    "plt.xlabel(\"Style de peinture\")\n",
    "plt.ylabel(\"Nombre d'artistes\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artiste ayant le plus d'œuvres\n",
    "artist_max = artists.loc[artists['paintings'].idxmax()]\n",
    "print(\"Artiste avec le plus d'œuvres :\")\n",
    "print(\"Nom :\", artist_max['name'])\n",
    "print(\"Nombre d'œuvres :\", artist_max['paintings'])\n",
    "print(\"Genre :\", artist_max['genre'])\n",
    "\n",
    "# Artiste ayant le moins d'œuvres\n",
    "artist_min = artists.loc[artists['paintings'].idxmin()]\n",
    "print(\"\\nArtiste avec le moins d'œuvres :\")\n",
    "print(\"Nom :\", artist_min['name'])\n",
    "print(\"Nombre d'œuvres :\", artist_min['paintings'])\n",
    "print(\"Genre :\", artist_min['genre'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db00aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du nombre total d'œuvres par genre\n",
    "genre_paintings = artists.groupby('genre')['paintings'].sum()\n",
    "\n",
    "# Création de l'histogramme\n",
    "genre_paintings.plot(kind='bar', color='lightblue', edgecolor='black')\n",
    "plt.title(\"Nombre total d'œuvres par genre\")\n",
    "plt.xlabel(\"Genre de peinture\")\n",
    "plt.ylabel(\"Nombre total d'œuvres\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468053d5",
   "metadata": {},
   "source": [
    "On voit que la majorité des artistes ont un nombre d'oeuvre compris entre 100 et 200. Nous allons zoomer sur cette zone, de sorte à ce que nous puissions mieux observer les nombres d'oeuvres par artistes.\n",
    "Néanmoins, on peut noter qu'un artiste  à plus de 800 oeuvres ( Vincent Van Gogh avec 877 oeuvres) et un artiste a 24 oeuvres (Jackson Pollock).\n",
    "Cependant, en observant le nombre d'artiste par genre, on remarque que J. Pollock est le seul artiste dans sa catégorie, tandis que la catégorie de V. Van Gogh compte le plus d'artiste. De plus, en observant le nombre d'oeuvre par genre, on observe que le post impressionim compte beaucoup plus d'oeuvres que l'Expressionism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse descriptive des artistes et des genre\n",
    "print(\"Nombre total d'artistes :\", artists['name'].nunique())\n",
    "print(\"Nombre total de styles :\", artists['genre'].nunique())\n",
    "\n",
    "# Distribution des œuvres par artiste\n",
    "artists['paintings'].plot(kind='hist', bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Distribution des œuvres par artiste\")\n",
    "plt.xlabel(\"Nombre d'œuvres\")\n",
    "plt.ylabel(\"Nombre d'artistes\")\n",
    "plt.xlim(0, 200)  # Limite de l'axe x\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451fabcd",
   "metadata": {},
   "source": [
    "maintenant que la distrbution des genre et des artistes est bien comprises, nous allons nous mener une analyse des périodes de vie des artistes; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sépare la colonne 'year' en deux colonnes : 'birth_year' et 'death_year'\n",
    "artists[['birth_year', 'death_year']] = artists['years'].str.split('-', expand=True)\n",
    "\n",
    "# Conversion des nouvelles colonnes en format numérique\n",
    "artists['birth_year'] = pd.to_numeric(artists['birth_year'], errors='coerce')\n",
    "artists['death_year'] = pd.to_numeric(artists['death_year'], errors='coerce')\n",
    "\n",
    "# Histogramme des années de naissance des artistes\n",
    "artists['birth_year'].dropna().plot(kind='hist', bins=20, color='salmon', edgecolor='black')\n",
    "plt.title(\"Distribution des années de naissance des artistes\")\n",
    "plt.xlabel(\"Année de naissance\")\n",
    "plt.ylabel(\"Nombre d'artistes\")\n",
    "plt.show()\n",
    "\n",
    "# Histogramme des années de décès des artistes\n",
    "artists['death_year'].dropna().plot(kind='hist', bins=20, color='purple', edgecolor='black')\n",
    "plt.title(\"Distribution des années de décès des artistes\")\n",
    "plt.xlabel(\"Année de décès\")\n",
    "plt.ylabel(\"Nombre d'artistes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists['birth_year'] = pd.to_numeric(artists['birth_year'], errors='coerce')\n",
    "artists['death_year'] = pd.to_numeric(artists['death_year'], errors='coerce')\n",
    "\n",
    "artists['life_duration'] = artists['death_year'] - artists['birth_year']\n",
    "artists['life_duration'] = artists['life_duration'].dropna()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "artists['life_duration'].plot(kind='hist', bins=20, color='purple', edgecolor='black')\n",
    "plt.title('Distribution de la durée de vie des artistes')\n",
    "plt.xlabel('Durée de vie (en années)')\n",
    "plt.ylabel('Nombre d\\'artistes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d756a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la durée de vie des artistes\n",
    "artists['birth_year'] = pd.to_numeric(artists['birth_year'], errors='coerce')\n",
    "artists['death_year'] = pd.to_numeric(artists['death_year'], errors='coerce')\n",
    "artists['life_duration'] = artists['death_year'] - artists['birth_year']\n",
    "\n",
    "# Identification de l'artiste avec la plus grande durée de vie\n",
    "longest_lived_artist = artists.loc[artists['life_duration'].idxmax()]\n",
    "longest_lived_name = longest_lived_artist['name']\n",
    "longest_lived_paintings = longest_lived_artist['paintings']\n",
    "longest_lived_duration = longest_lived_artist['life_duration']\n",
    "\n",
    "# Identification de l'artiste avec la durée de vie la plus courte\n",
    "shortest_lived_artist = artists.loc[artists['life_duration'].idxmin()]\n",
    "shortest_lived_name = shortest_lived_artist['name']\n",
    "shortest_lived_paintings = shortest_lived_artist['paintings']\n",
    "shortest_lived_duration = shortest_lived_artist['life_duration']\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Artiste avec la plus grande durée de vie : {longest_lived_name} ({longest_lived_paintings} œuvres, {longest_lived_duration} ans)\")\n",
    "print(f\"Artiste avec la durée de vie la plus courte : {shortest_lived_name} ({shortest_lived_paintings} œuvre(s), {shortest_lived_duration} ans)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17914f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = artists['life_duration'].corr(artists['paintings'])\n",
    "print(f\"Corrélation entre durée de vie et nombre d’œuvres : {correlation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e06ade9",
   "metadata": {},
   "source": [
    "Nous observons que la majorité des artistes ont émergé à partir de 1800. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# 1. Distribution des nationalités\n",
    "nationality_counts = artists['nationality'].value_counts()\n",
    "print(\"Nombre d'artistes par nationalité :\")\n",
    "print(nationality_counts)\n",
    "\n",
    "# 2. Visualisation des 10 nationalités les plus représentées\n",
    "top_nationalities = nationality_counts.head(10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_nationalities.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title(\"Les 10 nationalités les plus représentées parmi les artistes\")\n",
    "plt.xlabel(\"Nationalité\")\n",
    "plt.ylabel(\"Nombre d'artistes\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 3. Nationalités les plus et les moins représentées\n",
    "most_represented_nationality = nationality_counts.idxmax()\n",
    "least_represented_nationality = nationality_counts.idxmin()\n",
    "\n",
    "print(f\"Nationalité la plus représentée : {most_represented_nationality} ({nationality_counts.max()} artistes)\")\n",
    "print(f\"Nationalité la moins représentée : {least_represented_nationality} ({nationality_counts.min()} artiste(s))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Groupement par nationalité et somme des œuvres par pays\n",
    "country_paintings = artists.groupby('nationality')['paintings'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Nombre d'œuvres par pays :\")\n",
    "print(country_paintings)\n",
    "\n",
    "# 2. Visualisation des 10 pays les plus représentés en termes d'œuvres\n",
    "top_countries = country_paintings.head(10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_countries.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title(\"Les 10 pays avec le plus d'œuvres d'art\")\n",
    "plt.xlabel(\"Pays\")\n",
    "plt.ylabel(\"Nombre d'œuvres\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 3. Pays avec le plus et le moins d'œuvres\n",
    "most_paintings_country = country_paintings.idxmax()\n",
    "least_paintings_country = country_paintings.idxmin()\n",
    "\n",
    "print(f\"Pays avec le plus d'œuvres : {most_paintings_country} ({country_paintings.max()} œuvres)\")\n",
    "print(f\"Pays avec le moins d'œuvres : {least_paintings_country} ({country_paintings.min()} œuvre(s))\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a07ce9a",
   "metadata": {},
   "source": [
    "Nous observons que la majorité des artistes sont français ou italien, tandis que les artistes les moins nombeux sont orginaires de Belgique, d'Autriche, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075ec5a",
   "metadata": {},
   "source": [
    "En outre, nous observons que la France est le pays contenant le plus d'oeuvre, suivi de l'Allemagne. L'Italie arrive en 4ème position, alors qu'elle compte deux fois plus d'artistes que l'Allemagne (4 artistes). Cela nous montre qu'un nombre plus élevé d'artiste dans un pays n'implique pas forcément un plus grand nombre d'oeuvres produites par ces artistes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4473c70-edc9-42be-941d-4ad046393770",
   "metadata": {},
   "source": [
    "## Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7c2c3-d39a-4c55-ab73-26b09cde18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "\n",
    "# For HQ images only\n",
    "IMAGE_HQ_SIZE = 224\n",
    "MEAN_HQ = [0.485, 0.456, 0.406]\n",
    "STD_HQ = [0.229, 0.224, 0.225]\n",
    "TRANSFORM_HQ = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),  # Interpolate\n",
    "    #transforms.Pad((32, 32, 32, 32)),  # Padding\n",
    "    transforms.CenterCrop(224),  # Center\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN_HQ, std=STD_HQ)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9fc294-4296-4785-908c-43784d95318f",
   "metadata": {},
   "source": [
    "## Creating LQ images loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d861a-d229-4727-af05-2020b0adad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading LQ images\n",
    "images_lq_path = data_path + \"images_lq/\"\n",
    "images_filename = os.listdir(images_lq_path)\n",
    "\n",
    "list_name = []\n",
    "\n",
    "for filename in images_filename:\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) > 2:\n",
    "        name_surname = f\"{parts[0]} {parts[1]}\"\n",
    "    elif len(parts) == 2:  # \"Name_xxx\" format\n",
    "        name_surname = parts[0]  # Only Name\n",
    "    list_name.append(name_surname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa61d8-90ab-44b5-b8b3-a74c8e157c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(images_filename) == len(list_name):\n",
    "    total_lq_df = pd.DataFrame({\n",
    "        'filename': images_filename,  # Liste des noms de fichiers\n",
    "        'artist': list_name,          # Liste des artistes pour chaque peinture\n",
    "    })\n",
    "    print(\"DataFrame created successfully!\")\n",
    "else:\n",
    "    print(\"Error: The lists have different lengths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09f182-fc14-4abe-9155-9279568b3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints df if previously created\n",
    "total_lq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efe6e2c-84f7-4759-ab1b-40561e4687f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_LQ_SIZE = 64\n",
    "DATASET_LQ_SIZE = len(images_filename)\n",
    "CHANNELS = 3\n",
    "\n",
    "def load_image_as_rgb_matrices(image_name):    \n",
    "    img = Image.open(images_lq_path + image_name)\n",
    "    img = img.resize((IMAGE_LQ_SIZE, IMAGE_LQ_SIZE))  \n",
    "    img = img.convert('RGB')\n",
    "    return np.array(img)\n",
    "\n",
    "x = np.zeros((DATASET_LQ_SIZE, IMAGE_LQ_SIZE, IMAGE_LQ_SIZE, CHANNELS))\n",
    "for i in range(DATASET_LQ_SIZE):\n",
    "    x[i] = load_image_as_rgb_matrices(images_filename[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a38021-7f61-447d-9d9c-9bbabd38ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few plots\n",
    "number_of_plots = 3\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(number_of_plots * 2, 2))\n",
    "\n",
    "for i in range(number_of_plots):\n",
    "    axes[i].imshow(x[i*100]/255.0)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f\"{list_name[i*100]}\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5db7f5-7abd-4883-b7f2-3e4230fbaf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the artists\n",
    "classes = np.array(list(set(total_lq_df['artist'])))\n",
    "classes_as_int = np.array([np.where(classes == artist)[0][0] for artist in total_lq_df['artist']])\n",
    "\n",
    "x_train, x_test_val, y_train, y_test_val = train_test_split(\n",
    "    np.transpose(x, (0, 3, 1, 2)),  classes_as_int, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(\n",
    "    x_test_val, y_test_val, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Normalize images\n",
    "x_train, x_val, x_test = x_train / 255.0, x_val / 255.0, x_test / 255.0\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset_lq = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset_lq = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "test_dataset_lq = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader_lq = DataLoader(train_dataset_lq, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_lq = DataLoader(val_dataset_lq, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader_lq = DataLoader(test_dataset_lq, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset_lq)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset_lq)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset_lq)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688b540b-feab-4acc-9e94-a618baa0b9bf",
   "metadata": {},
   "source": [
    "## Creating HQ images loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75579f32-cc21-489e-bdc1-2e38e86e16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading HQ images\n",
    "gc = \"./art-challenge/images_hq\"\n",
    "dataset_hq = datasets.ImageFolder(root=gc, transform=TRANSFORM_HQ)\n",
    "DATASET_HQ_SIZE = len(dataset_hq)\n",
    "dataset_hq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ff09b-291c-4629-af66-69e5bb864a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * DATASET_HQ_SIZE)  # 70% \n",
    "val_size = int(0.1 * DATASET_HQ_SIZE)   # 15% \n",
    "test_size = DATASET_HQ_SIZE - train_size - val_size\n",
    "\n",
    "train_dataset_hq, val_dataset_hq, test_dataset_hq = random_split(dataset_hq, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader_hq = DataLoader(train_dataset_hq, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_hq = DataLoader(val_dataset_hq, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader_hq = DataLoader(test_dataset_hq, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset_hq)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset_hq)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset_hq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40c413-71e8-47a8-9a3a-5806aca83537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, labels, nb_images = 4):\n",
    "    if not nb_images <= BATCH_SIZE:\n",
    "        return\n",
    "        \n",
    "    images = images.permute(0, 2, 3, 1)  # From (batch, C, H, W) to (batch, H, W, C)\n",
    "    \n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "    images = images * std + mean\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy())\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Label: {labels[i]}')\n",
    "    plt.show()\n",
    "\n",
    "# Print few images\n",
    "data_iter = iter(train_loader_hq)\n",
    "images, labels = next(data_iter)\n",
    "show_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dc463a-f19c-4641-be40-ceccc6be8137",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b2df6-34f8-4991-af6c-3d18331b7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(dataset_hq.classes) # Same value for lQ dataset\n",
    "DROPOUT_RATE = 0.4\n",
    "\n",
    "def get_model(name='resnet18', weights='IMAGENET1K_V1', verbose=False):\n",
    "    model = getattr(models, name)(weights=weights)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(p=DROPOUT_RATE),                  \n",
    "        nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    ) \n",
    "\n",
    "    if verbose:\n",
    "        trainable_params =  sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f'Trainable params: {trainable_params}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc92bc-9a9c-4219-a661-3be1aee4d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use Optuna to optimize the best hyper-params\n",
    "# Long time execution...\n",
    "# See https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_simple.py\n",
    "def objective(trial):\n",
    "    # Define the model\n",
    "    model = get_model()\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # The different parameters we're trying to improve\n",
    "    fc_lr = trial.suggest_float(\"fc_lr\", 1e-4, 1e-2, log=True)  \n",
    "    base_lr = trial.suggest_float(\"base_lr\", 1e-6, 1e-4, log=True)\n",
    "    \n",
    "    base_params = [p for name, p in model.named_parameters() if \"fc\" not in name]\n",
    "    \n",
    "    # Init optimizer\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': model.fc.parameters(), 'lr': fc_lr},      # LR for fully connected layer\n",
    "        {'params': base_params, 'lr': base_lr}               # LR for pretrained layers\n",
    "    ])\n",
    "\n",
    "    # Loss\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum') \n",
    "    \n",
    "    # Training of the model\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total_train_samples = 0\n",
    "        correct_train = 0\n",
    "        for images, labels in tqdm(train_loader_hq):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # FB\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # BW\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Do not need to apply softmax manually -> this order will be the same\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            total_train_samples += images.size(0)\n",
    "        \n",
    "        train_loss = train_loss / total_train_samples\n",
    "        train_accuracy = correct_train / total_train_samples\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_val_samples = 0\n",
    "        correct_val = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader_hq):\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                total_val_samples += images.size(0)\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_val += (preds == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / total_val_samples\n",
    "        val_accuracy = correct_val / total_val_samples\n",
    "        \n",
    "        # Train accuracy could be used to check if the network learns something\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        trial.report(val_accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb3d6fc-1aa0-478f-9fd4-c7784505f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default sampler used: https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
