{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# Project CVAE on MNIST datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Fashion-MNIST datasets\n",
    "# Note: to improve speed we could save images as flatten images (using tranform for example)\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation between VAE and Conditional VAE (CVAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources :\n",
    "- https://proceedings.neurips.cc/paper/2015/file/8d55a249e6baa5c06772297520da2051-Paper.pdf\n",
    "- https://arxiv.org/pdf/1312.6114\n",
    "- https://lilianweng.github.io/posts/2018-08-12-vae/\n",
    "\n",
    "In addition of the input data, the CVAE takes a conditional variable (a class label in our case) in input of both encoder and decoder. The goal of a CVAE is to shape the latent shape to correspond to the condition variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global values\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "MAX_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-3\n",
    "CLASSES_TO_IDX = train_dataset.class_to_idx\n",
    "FEATURE_SIZE = train_dataset.data[0].shape[0]\n",
    "CLASS_SIZE = 10\n",
    "LATENT_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choice of hyperparameters :\n",
    "- `BATCH_SIZE` :\n",
    "- `MAX_EPOCHS` :\n",
    "- `LEARNING_RATE` :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVAE implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first image of each dataset\n",
    "# Note: Do not run it after splitting datas into validation and test sets\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))\n",
    "\n",
    "axs[0].imshow(train_dataset.data[100], cmap='gray')\n",
    "axs[0].set_title(f\"{list(CLASSES_TO_IDX.keys())[train_dataset.targets[100]]}\")\n",
    "\n",
    "axs[1].imshow(test_dataset.data[0], cmap='gray')\n",
    "axs[1].set_title(f\"{list(CLASSES_TO_IDX.keys())[test_dataset.targets[0]]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test between validation and test\n",
    "val_size = int(test_dataset.data.shape[0] / 2)\n",
    "test_size = test_dataset.data.shape[0] - val_size\n",
    "test_dataset, val_dataset = random_split(test_dataset, [test_size, val_size])\n",
    "\n",
    "# Some prints\n",
    "print(f\"Train dataset size: {len(train_dataset.data)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Makes dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://github.com/unnir/cVAE/blob/master/cvae.py\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, feature_size, latent_size, class_size):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.class_size = class_size\n",
    "\n",
    "        # encode\n",
    "        self.fc1  = nn.Linear(feature_size * feature_size + class_size, 400)\n",
    "        self.fc21 = nn.Linear(400, latent_size)\n",
    "        self.fc22 = nn.Linear(400, latent_size)\n",
    "\n",
    "        # decode\n",
    "        self.fc3 = nn.Linear(latent_size + class_size, 400)\n",
    "        self.fc4 = nn.Linear(400, feature_size * feature_size)\n",
    "\n",
    "        self.elu = nn.ELU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Center for each class in latent space\n",
    "        self.class_centers = nn.Parameter(torch.randn(class_size, latent_size))\n",
    "\n",
    "    def encode(self, x, c): # Q(z|x, c)\n",
    "        inputs = torch.cat([x, c], 1)\n",
    "        h1 = self.elu(self.fc1(inputs))\n",
    "        z_mu = self.fc21(h1)\n",
    "        z_var = self.fc22(h1)\n",
    "        return z_mu, z_var\n",
    "\n",
    "    def sample(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z, c): # P(x|z, c)\n",
    "        inputs = torch.cat([z, c], 1)\n",
    "        h3 = self.elu(self.fc3(inputs))\n",
    "        recon = self.sigmoid(self.fc4(h3))\n",
    "        return recon.view(inputs.size(0), 1, self.feature_size, self.feature_size)\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mu, logvar = self.encode(x, c)\n",
    "        z = self.sample(mu, logvar)\n",
    "        return self.decode(z, c), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar, beta=1):\n",
    "    recon_x = recon_x.view(recon_x.size(0), -1)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + beta * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, class_size):\n",
    "    targets = torch.zeros(labels.size(0), class_size)\n",
    "    for i, label in enumerate(labels):\n",
    "        targets[i, label] = 1\n",
    "    return targets.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae = CVAE(FEATURE_SIZE, LATENT_SIZE, CLASS_SIZE)\n",
    "cvae.to(DEVICE)\n",
    "optimizer = optim.Adam(cvae.parameters(), lr=LEARNING_RATE)\n",
    "# StepLR Scheduler (réduit le learning rate de gamma, donc ici 0.1, toutes les 10 epochs)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "val_loss_l = torch.zeros(MAX_EPOCHS)\n",
    "train_loss_l = torch.zeros(MAX_EPOCHS)\n",
    "\n",
    "for epoch in range(1, MAX_EPOCHS + 1):\n",
    "    # On affiche le learning rate actuel\n",
    "    current_lr = get_lr(optimizer)\n",
    "    print(f\"Epoch {epoch}/{MAX_EPOCHS} - Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    # Training part\n",
    "    cvae.train()\n",
    "    running_train_loss = 0.0\n",
    "    t_train = tqdm(train_loader, desc=f\"Epoch {epoch}/{MAX_EPOCHS} Training\")\n",
    "    for data, labels in t_train:\n",
    "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "        labels = one_hot(labels, CLASS_SIZE)\n",
    "        recon_batch, mu, logvar = cvae(data, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "    train_loss = running_train_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Validation part\n",
    "    cvae.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        running_val_loss = 0.0\n",
    "        t_val = tqdm(val_loader, desc=f\"Epoch {epoch}/{MAX_EPOCHS} Validation\")\n",
    "        for data, labels in t_val:\n",
    "            data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "            labels = one_hot(labels, CLASS_SIZE)\n",
    "            recon_batch, mu, logvar = cvae(data, labels)            \n",
    "            loss = loss_function(recon_batch, data, mu, logvar)\n",
    "\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "    val_loss = running_val_loss / len(val_loader.dataset)\n",
    "\n",
    "    train_loss_l[epoch - 1] = train_loss\n",
    "    val_loss_l[epoch - 1] = val_loss\n",
    "    \n",
    "    print(f'Epoch {epoch}, Training loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}')\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "plt.plot(train_loss_l)\n",
    "plt.title(\"Train loss\")\n",
    "plt.show()\n",
    "plt.plot(val_loss_l)\n",
    "plt.title(\"Validation loss\")\n",
    "plt.show()\n",
    "# Saving part (if needed)\n",
    "torch.save(cvae.state_dict(), 'cvae_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "cvae = CVAE(FEATURE_SIZE, LATENT_SIZE, CLASS_SIZE)\n",
    "cvae.to(DEVICE)\n",
    "cvae.load_state_dict(torch.load('cvae_weights.pth', weights_only=True))\n",
    "cvae.eval()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter([], [], c=[], cmap='tab10', vmin=0, vmax=9)\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_test_loss = 0.0\n",
    "    total_mse = 0.0\n",
    "    number_images = 0\n",
    "    residuals_sum = 0\n",
    "    t_test = tqdm(test_loader, desc=\"Testing...\")\n",
    "    for data, labels in t_test:\n",
    "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "        labels = one_hot(labels, CLASS_SIZE)\n",
    "        recon_batch, mu, logvar = cvae(data, labels) \n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        mse_value = F.mse_loss(recon_batch, data, reduction='sum') \n",
    "        total_mse += mse_value.item()\n",
    "        residuals_sum += torch.abs(data - recon_batch).sum(dim=0) # (1, 28, 28) where 1 is the channel number\n",
    "        number_images += labels.size(0)\n",
    "\n",
    "        running_test_loss += loss.item()\n",
    "\n",
    "        # Plot part\n",
    "        mu, labels = mu.cpu(), labels.cpu()\n",
    "        scatter = ax.scatter(mu[:,0], mu[:,1], c=[labels.argmax(dim=1)], cmap='tab10', vmin=0, vmax=9)        \n",
    "        \n",
    "test_loss = running_test_loss / len(test_loader.dataset)\n",
    "MSE = total_mse / number_images\n",
    "print(f\"Test loss: {test_loss} -- MSE: {MSE}\")\n",
    "\n",
    "plt.colorbar(scatter)\n",
    "plt.title(\"Latent Space\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "residuals_mean = residuals_sum / number_images\n",
    "residuals_mean_np = residuals_mean.cpu().numpy().squeeze()  # (28, 28) The squeeze is used to delete channel dim\n",
    "\n",
    "plt.imshow(residuals_mean_np, cmap='hot')\n",
    "plt.title('Residuals')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes some plots\n",
    "def plot_test(cvae):\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(6,6))\n",
    "\n",
    "    loader_iter = iter(test_loader)\n",
    "\n",
    "    data1, labels1 = next(loader_iter)\n",
    "    data1, labels1 = data1.to(DEVICE), labels1.to(DEVICE)\n",
    "    labels1 = one_hot(labels1, CLASS_SIZE)\n",
    "    recon1, _, _ = cvae(data1, labels1)\n",
    "\n",
    "    data2, labels2 = next(loader_iter)\n",
    "    data2, labels2 = data2.to(DEVICE), labels2.to(DEVICE)\n",
    "    labels2 = one_hot(labels2, CLASS_SIZE)\n",
    "    recon2, _, _ = cvae(data2, labels2)\n",
    "\n",
    "    # Moving back to cpu\n",
    "    data1, data2 = data1.cpu(), data2.cpu()\n",
    "    labels1, labels2 = labels1.cpu(), labels2.cpu()\n",
    "    recon1, recon2 = recon1.detach().cpu(), recon2.detach().cpu()\n",
    "\n",
    "    # Plots\n",
    "    i = random.randint(0, BATCH_SIZE - 1)\n",
    "    axs[0,0].imshow(data1[i].squeeze(), cmap='gray')\n",
    "    axs[0,0].set_title(f\"{list(CLASSES_TO_IDX.keys())[labels1[i].argmax()]}\")\n",
    "\n",
    "    axs[0,1].imshow(data2[i].squeeze(), cmap='gray')\n",
    "    axs[0,1].set_title(f\"{list(CLASSES_TO_IDX.keys())[labels2[i].argmax()]}\")\n",
    "\n",
    "    axs[1,0].imshow(recon1[i].squeeze(), cmap='gray')\n",
    "    axs[1,1].imshow(recon2[i].squeeze(), cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    pass\n",
    "plot_test(cvae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Une autre Loss pour ne pas avoir des classes superposées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cette perte fonctionne en choisissant trois exemples :\n",
    "#Ancre : un point latent de la classe cible.\n",
    "#Positif : un autre point latent de la même classe.\n",
    "#Négatif : un point latent d'une classe différente.\n",
    "#La triplet loss pousse l’ancre et le positif à se rapprocher, et l’ancre et le négatif à s'éloigner. Cela peut être plus efficace pour séparer les classes.\n",
    "\n",
    "def triplet_loss(mu, labels, margin=1.0):\n",
    "    batch_size = mu.size(0)\n",
    "    loss = 0\n",
    "    for i in range(batch_size):\n",
    "        anchor = mu[i]\n",
    "        pos_indices = (labels == labels[i]).nonzero().view(-1)\n",
    "        neg_indices = (labels != labels[i]).nonzero().view(-1)\n",
    "        \n",
    "        if len(pos_indices) > 1 and len(neg_indices) > 0:\n",
    "            pos_index = pos_indices[torch.randint(1, len(pos_indices), (1,))].item()\n",
    "            neg_index = neg_indices[torch.randint(0, len(neg_indices), (1,))].item()\n",
    "            positive = mu[pos_index]\n",
    "            negative = mu[neg_index]\n",
    "            \n",
    "            # Triplet loss calculation\n",
    "            pos_dist = torch.sum((anchor - positive) ** 2)\n",
    "            neg_dist = torch.sum((anchor - negative) ** 2)\n",
    "            loss += torch.relu(pos_dist - neg_dist + margin)\n",
    "    loss /= batch_size\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_loss(recon_x, x, mu, logvar, labels, class_centers, beta=1, lambda_center=0.1, lambda_triplet=5):\n",
    "    # Reconstruction loss\n",
    "    recon_x = recon_x.view(recon_x.size(0), -1)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # KL Divergence\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    # Center loss\n",
    "    batch_size = mu.size(0)\n",
    "    center_loss = 0\n",
    "    for i in range(batch_size):\n",
    "        target_center = class_centers[labels[i].argmax()]  # get the center for the correct class\n",
    "        center_loss += torch.sum((mu[i] - target_center) ** 2)  # distance to the target center\n",
    "    center_loss /= batch_size\n",
    "    \n",
    "    # Triplet loss for better separation\n",
    "    triplet_loss_value = triplet_loss(mu, labels.argmax(dim=1))\n",
    "    \n",
    "    # Total loss with center loss and triplet loss\n",
    "    return BCE + beta * KLD + lambda_center * center_loss + lambda_triplet * triplet_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_new_loss = CVAE(FEATURE_SIZE, LATENT_SIZE, CLASS_SIZE)\n",
    "cvae_new_loss.to(DEVICE)\n",
    "optimizer = optim.Adam(cvae_new_loss.parameters(), lr=LEARNING_RATE)\n",
    "# StepLR Scheduler (réduit le learning rate de gamma, donc ici 0.1, toutes les 10 epochs)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "MAX_EPOCHS = 10\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "train_loss_triplet = torch.zeros(MAX_EPOCHS)\n",
    "val_loss_triplet = torch.zeros(MAX_EPOCHS)\n",
    "for epoch in range(1, MAX_EPOCHS + 1):\n",
    "    # On affiche le learning rate actuel\n",
    "    current_lr = get_lr(optimizer)\n",
    "    print(f\"Epoch {epoch}/{MAX_EPOCHS} - Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    # Training part\n",
    "    cvae_new_loss.train()\n",
    "    running_train_loss = 0.0\n",
    "    t_train = tqdm(train_loader, desc=f\"Epoch {epoch}/{MAX_EPOCHS} Training\")\n",
    "    for data, labels in t_train:\n",
    "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "        labels = one_hot(labels, CLASS_SIZE)\n",
    "        recon_batch, mu, logvar = cvae_new_loss(data, labels)\n",
    "        optimizer.zero_grad()\n",
    "        beta = min(0.01 , 0.2 )  # augmenter progressivement jusqu'à target_beta\n",
    "        lambda_triplet = min(2+ epoch * 0.5, 8)  # target_lambda_triplet peut être fixé à 15 ou 20\n",
    "        loss = new_loss(recon_batch, data, mu, logvar, labels, cvae_new_loss.class_centers, beta=beta, lambda_triplet=lambda_triplet)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "    train_loss = running_train_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Validation part\n",
    "    cvae_new_loss.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        running_val_loss = 0.0\n",
    "        t_val = tqdm(val_loader, desc=f\"Epoch {epoch}/{MAX_EPOCHS} Validation\")\n",
    "        for data, labels in t_val:\n",
    "            data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "            labels = one_hot(labels, CLASS_SIZE)\n",
    "            recon_batch, mu, logvar = cvae_new_loss(data, labels)            \n",
    "            loss = new_loss(recon_batch, data, mu, logvar, labels, cvae_new_loss.class_centers)\n",
    "\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "    val_loss = running_val_loss / len(val_loader.dataset)\n",
    "\n",
    "    val_loss_triplet[epoch-1] = val_loss\n",
    "    train_loss_triplet[epoch-1] = train_loss\n",
    "    \n",
    "    print(f'Epoch {epoch}, Training loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}')\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "plt.plot(train_loss_triplet)\n",
    "plt.title(\"Train loss with the Triplet Loss\")\n",
    "plt.show()\n",
    "plt.plot(val_loss_triplet)\n",
    "plt.title(\"Validation loss with the Triplet Loss\")\n",
    "plt.show()\n",
    "\n",
    "# Saving part (if needed)\n",
    "torch.save(cvae_new_loss.state_dict(), 'cvae_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter([], [], c=[], cmap='tab10', vmin=0, vmax=9)\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_test_loss = 0.0\n",
    "    total_mse = 0.0\n",
    "    number_images = 0\n",
    "    residuals_sum = 0\n",
    "    t_test = tqdm(test_loader, desc=\"Testing...\")\n",
    "    for data, labels in t_test:\n",
    "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "        labels = one_hot(labels, CLASS_SIZE)\n",
    "        recon_batch, mu, logvar = cvae_new_loss(data, labels) \n",
    "        loss = new_loss(recon_batch, data, mu, logvar, labels, cvae_new_loss.class_centers)\n",
    "        mse_value = F.mse_loss(recon_batch, data, reduction='sum') \n",
    "        total_mse += mse_value.item()\n",
    "        residuals_sum += torch.abs(data - recon_batch).sum(dim=0) # (1, 28, 28) where 1 is the channel number\n",
    "        number_images += labels.size(0)\n",
    "\n",
    "        running_test_loss += loss.item()\n",
    "\n",
    "        # Plot part\n",
    "        mu, labels = mu.cpu(), labels.cpu()\n",
    "        scatter = ax.scatter(mu[:,0], mu[:,1], c=[labels.argmax(dim=1)], cmap='tab10', vmin=0, vmax=9)        \n",
    "        \n",
    "test_loss = running_test_loss / len(test_loader.dataset)\n",
    "MSE = total_mse / number_images\n",
    "print(f\"Test loss: {test_loss} -- MSE: {MSE}\")\n",
    "\n",
    "plt.colorbar(scatter)\n",
    "plt.title(\"Latent Space\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test(cvae_new_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
